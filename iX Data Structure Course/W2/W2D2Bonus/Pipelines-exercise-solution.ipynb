{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genre</th>\n",
       "      <th>original_language</th>\n",
       "      <th>popularity</th>\n",
       "      <th>production_company</th>\n",
       "      <th>production_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>title</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Father of the Bride Collection</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>8.387519</td>\n",
       "      <td>Sandollar Productions</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1995-02-10</td>\n",
       "      <td>76578911.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Drama</td>\n",
       "      <td>en</td>\n",
       "      <td>0.894647</td>\n",
       "      <td>Miramax</td>\n",
       "      <td>South Africa</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>676525.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>Cry, the Beloved Country</td>\n",
       "      <td>6.7</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Friday Collection</td>\n",
       "      <td>3500000.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>14.569650</td>\n",
       "      <td>New Line Cinema</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1995-04-26</td>\n",
       "      <td>28215918.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>7.0</td>\n",
       "      <td>513.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>8.963037</td>\n",
       "      <td>Paramount Pictures</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1996-02-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Black Sheep</td>\n",
       "      <td>6.0</td>\n",
       "      <td>124.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>12000000.0</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>en</td>\n",
       "      <td>9.592265</td>\n",
       "      <td>Universal Pictures</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>1996-02-16</td>\n",
       "      <td>41205099.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>Happy Gilmore</td>\n",
       "      <td>6.5</td>\n",
       "      <td>767.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            belongs_to_collection      budget   genre original_language  \\\n",
       "0  Father of the Bride Collection         NaN  Comedy                en   \n",
       "1                             NaN         NaN   Drama                en   \n",
       "2               Friday Collection   3500000.0  Comedy                en   \n",
       "3                             NaN         NaN  Comedy                en   \n",
       "4                             NaN  12000000.0  Comedy                en   \n",
       "\n",
       "   popularity     production_company        production_country release_date  \\\n",
       "0    8.387519  Sandollar Productions  United States of America   1995-02-10   \n",
       "1    0.894647                Miramax              South Africa   1995-12-15   \n",
       "2   14.569650        New Line Cinema  United States of America   1995-04-26   \n",
       "3    8.963037     Paramount Pictures  United States of America   1996-02-01   \n",
       "4    9.592265     Universal Pictures  United States of America   1996-02-16   \n",
       "\n",
       "      revenue  runtime                        title  vote_average  vote_count  \n",
       "0  76578911.0    106.0  Father of the Bride Part II           5.7       173.0  \n",
       "1    676525.0    106.0     Cry, the Beloved Country           6.7        13.0  \n",
       "2  28215918.0     91.0                       Friday           7.0       513.0  \n",
       "3        32.0     87.0                  Black Sheep           6.0       124.0  \n",
       "4  41205099.0     92.0                Happy Gilmore           6.5       767.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "movies = pd.read_csv(\"data/movies.1.initial_process.csv\")\n",
    "movies = movies[movies.status==\"Released\"]\n",
    "del movies[\"status\"]\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Pipeline that process the dataset. You have to make sure you deal accordingly with numerical, categorical and text variables. (Note: you dont have to use them all!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = movies.select_dtypes(np.number).columns\n",
    "categorical_cols = movies.select_dtypes(object).drop(columns=[\n",
    "                            \"belongs_to_collection\",\n",
    "                            \"title\",\n",
    "                            \"release_date\"\n",
    "    ]).columns\n",
    "date_col = [\"release_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlxtend'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-7465ce0c4f0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmlxtend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColumnSelector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlxtend'"
     ]
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ColumnSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Numerical pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnSelector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-e83a7e8221aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m numerical_pipeline = make_pipeline(\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mColumnSelector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumerical_cols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mimputer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mscaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ColumnSelector' is not defined"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "numerical_pipeline = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols),\n",
    "    imputer,\n",
    "    scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline.fit_transform(movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Categorical pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import OneHotEncoder\n",
    "\n",
    "categorical_pipeline = make_pipeline(\n",
    "    ColumnSelector(cols=categorical_cols),\n",
    "    OneHotEncoder()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline.fit_transform(movies).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: you could probably use the release date year as a categorical like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(movies.release_date).dt.year.astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processing_pipeline.fit_transform(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Ridge estimator to predict a movies revenue based on the other features. What is the optimal value of alpha to minimize the RMSE? *Hint*: You can use validation curves to figure it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"revenue\"\n",
    "numerical_cols_no_revenue = movies.drop(columns=target).select_dtypes(np.number).columns\n",
    "\n",
    "numerical_pipeline_no_revenue = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols_no_revenue),\n",
    "    imputer,\n",
    "    scaler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline_no_revenue = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline_no_revenue\n",
    ")\n",
    "movies_with_revenue = movies[movies.revenue.notnull()]\n",
    "processed_data_no_revenue = processing_pipeline_no_revenue.fit_transform(movies_with_revenue)\n",
    "target_revenue = movies_with_revenue.revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (12, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_alpha = np.linspace(0.001, 100, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse_cv(estimator, X, y):\n",
    "    y_pred = estimator.predict(X)\n",
    "    return np.sqrt(mean_squared_error(y_pred, y))\n",
    "\n",
    "estimator = Ridge()\n",
    "\n",
    "train_scores, test_scores = validation_curve(\n",
    "    estimator, \n",
    "    processed_data_no_revenue,\n",
    "    target_revenue,\n",
    "    param_name=\"alpha\", \n",
    "    param_range=range_alpha,\n",
    "    cv=3, \n",
    "    scoring=rmse_cv,\n",
    "    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.abs(np.mean(train_scores, axis=1))\n",
    "test_scores_mean = np.abs(np.mean(test_scores, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range_alpha, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "plt.plot(range_alpha, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Test score\")\n",
    "plt.title(\"Validation Curve: Ridge alpha value\")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"Root Mean Squared Error (RMSE)\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the training score increases but the test score flattens out around $\\alpha=90$. Since what we care the most is about the test score (the training score is nice but we care more about how the model generalizes on unseen data) we can use that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cross_val_score(Ridge(alpha=90),\n",
    "                          processed_data_no_revenue,\n",
    "                          target_revenue,\n",
    "                          scoring=rmse_cv,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1\n",
    "                         ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remember when we did exploratory data analyses and we groupd the numerical variables into quintiles? That is a valid technique used in Machine Learning to expand a dataset, it is called [Binning or Bucketing](http://blog.yhat.com/tutorials/5-Feature-Engineering.html).\n",
    "\n",
    "### Create your own transformer that given a numerical variable and a number of buckets returns the specificed quartile (so if we choose buckets = 4, it would return 1, 2,3 or 4 depending on each observation being on the 1st, 2nd, 3rd or 4th quartile).\n",
    "\n",
    "### Try putting your bucket transformer into a pipeline to make sure it works, and check if it improves the performance of your model.\n",
    "\n",
    "**Hint**: You can use `ColumnSelector` as a template, and you can check pandas `qcut` for the actual binning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A transformer must work with numpy arrays, and I would like it also to work with pandas dataframes as inputs. The output will be a numpy array.\n",
    "\n",
    "I found that for some columns I got the error:\n",
    "\n",
    "Which can be solved by setting the parameter `duplicates=\"drop\"` to qcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class QuantileBinner(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Transform a column and groups it into a specified number of buckets\n",
    "    \"\"\"\n",
    "    def __init__(self, bins):\n",
    "        self.bins = bins\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        output = pd.DataFrame()\n",
    "        if not hasattr(X, 'loc'):\n",
    "            # if the input doesnt have the method loc is a numpy array\n",
    "            input_data = pd.DataFrame(X)\n",
    "        else:\n",
    "            #only pandas dataframes have the method loc\n",
    "            input_data = X\n",
    "        for column in input_data.columns:\n",
    "            output = pd.concat([output, pd.qcut(\n",
    "                                            input_data[column],\n",
    "                                            self.bins,\n",
    "                                            duplicates=\"drop\").cat.codes], \n",
    "                                   axis=1)  \n",
    "        return output.values\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner = QuantileBinner(bins=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test  that it works with numpy arrays and pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner.fit_transform(movies[[\"budget\", \"popularity\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binner.fit_transform(movies[[\"budget\", \"popularity\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_pipeline_no_revenue_buckets = make_pipeline(\n",
    "    ColumnSelector(cols=numerical_cols_no_revenue),\n",
    "    imputer,\n",
    "    scaler,\n",
    "    binner\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_pipeline_no_revenue_buckets = make_union(\n",
    "    categorical_pipeline,\n",
    "    numerical_pipeline_no_revenue_buckets\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue_buckets = processing_pipeline_no_revenue_buckets.fit_transform(movies_with_revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_no_revenue_buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(Ridge(alpha=90),\n",
    "                          processed_data_no_revenue_buckets,\n",
    "                          target_revenue,\n",
    "                          scoring=rmse_cv,\n",
    "                          cv=3,\n",
    "                          n_jobs=-1\n",
    "                         ).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in this case it does not improve the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

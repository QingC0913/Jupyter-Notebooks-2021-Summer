{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first exercise we are going to use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), a classic one. Make sure you read the documentation for the dataset and explore it to make sure you know how to tackle the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed things up, we will get a sample of 10000 observations. I set numpy's random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15795,   860, 54886, ..., 49222, 48115, 40647])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "np.random.seed(42)\n",
    "random_sample_index = np.random.randint(0, mnist.data.shape[0], sample_size)\n",
    "random_sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_sample_data = mnist.data[random_sample_index]\n",
    "mnist_sample_target = mnist.target[random_sample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use PCA to reduce the mnist sample dimensionality and create a classifier that correctly classifies the images, using as the scorer the F1 score (there are multiple f1 scores for multiclass, choose the one you think fits best the problem, the [documentation can help](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)). A good classifier would have a F1 of above 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first we check how the target classes are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.1152\n",
       "3.0    0.1040\n",
       "7.0    0.1038\n",
       "0.0    0.1036\n",
       "4.0    0.1017\n",
       "2.0    0.0982\n",
       "9.0    0.0974\n",
       "8.0    0.0942\n",
       "6.0    0.0941\n",
       "5.0    0.0878\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mnist_sample_target).value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is no class imbalance, so we can use F1 micro average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pca = pca.fit_transform(mnist_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf_results = cross_val_score(clf,\n",
    "                              mnist_pca,\n",
    "                              mnist_target,\n",
    "                              scoring=\"f1_micro\",\n",
    "                              cv=3\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99689989994800321"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'>PCA exercise</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first exercise we are going to use the [MNIST dataset](http://yann.lecun.com/exdb/mnist/), a classic one. Make sure you read the documentation for the dataset and explore it to make sure you know how to tackle the exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists off 70000 images of handwritten digits, each one 28x28 pixels in black and white (0 being absolute black and 255 being absolute white). For convenience scikit-learn provides them as an array of 784 elements (28 x 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit = mnist.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   3.,  18.,\n",
       "        18.,  18., 126., 136., 175.,  26., 166., 255., 247., 127.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        30.,  36.,  94., 154., 170., 253., 253., 253., 253., 253., 225.,\n",
       "       172., 253., 242., 195.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  49., 238., 253., 253., 253., 253.,\n",
       "       253., 253., 253., 253., 251.,  93.,  82.,  82.,  56.,  39.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "        18., 219., 253., 253., 253., 253., 253., 198., 182., 247., 241.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,  80., 156., 107., 253.,\n",
       "       253., 205.,  11.,   0.,  43., 154.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,  14.,   1., 154., 253.,  90.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       139., 253., 190.,   2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  11., 190., 253.,  70.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  35., 241., 225., 160., 108.,   1.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  81., 240.,\n",
       "       253., 253., 119.,  25.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  45., 186., 253., 253., 150.,  27.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  16.,  93., 252., 253., 187.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 249., 253.,\n",
       "       249.,  64.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,  46., 130., 183., 253., 253., 207.,   2.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,  39., 148., 229., 253., 253., 253.,\n",
       "       250., 182.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  24., 114.,\n",
       "       221., 253., 253., 253., 253., 201.,  78.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,  23.,  66., 213., 253., 253., 253., 253., 198.,  81.,\n",
       "         2.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,  18., 171., 219., 253., 253.,\n",
       "       253., 253., 195.,  80.,   9.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  55.,\n",
       "       172., 226., 253., 253., 253., 253., 244., 133.,  11.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0., 136., 253., 253., 253., 212., 135.,\n",
       "       132.,  16.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAOTklEQVR4nO3dfYxUZZbH8d8RQVSIQWk7xCHbsxM1MSbTgyVZw0tYxiXIP2AwZkicsJFsT3xJBkPMGDZxfEkMMcuMGM0kPQvCbGYdRwHBxOyihMSQ6GipqIDvpgmNvDRRGSHKLHD2j75MWqx6qqm6Vbfo8/0knaq6p27fQ8GPW3Wfe+sxdxeAke+8ohsA0BqEHQiCsANBEHYgCMIOBHF+Kzc2ceJE7+rqauUmgVD6+vp0+PBhq1RrKOxmNlfSKkmjJP2nu69IPb+rq0vlcrmRTQJIKJVKVWt1v403s1GSnpR0k6RrJC0ys2vq/X0AmquRz+xTJX3i7p+5+98k/UnS/HzaApC3RsJ+haS9Qx73Z8u+w8x6zKxsZuWBgYEGNgegEU0/Gu/uve5ecvdSR0dHszcHoIpGwr5P0uQhj3+QLQPQhhoJ+xuSrjSzH5rZGEk/k7Q5n7YA5K3uoTd3P2Fmd0v6Xw0Ova1x9125dQYgVw2Ns7v7i5JezKkXAE3E6bJAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0dAsrmh/p06dStaPHz/e1O2vW7euau3YsWPJdXfv3p2sP/bYY8n68uXLq9aeeOKJ5LoXXnhhsr5y5cpk/Y477kjWi9BQ2M2sT9LXkk5KOuHupTyaApC/PPbs/+zuh3P4PQCaiM/sQBCNht0lbTGzN82sp9ITzKzHzMpmVh4YGGhwcwDq1WjYp7v7FEk3SbrLzGae+QR373X3kruXOjo6GtwcgHo1FHZ335fdHpK0UdLUPJoCkL+6w25mF5vZ+NP3Jc2RtDOvxgDkq5Gj8Z2SNprZ6d/z3+7+P7l0NcIcOXIkWT958mSy/s477yTrW7ZsqVr76quvkuv29vYm60Xq6upK1pctW5asr169umrtkksuSa47Y8aMZH327NnJejuqO+zu/pmkH+fYC4AmYugNCIKwA0EQdiAIwg4EQdiBILjENQf9/f3Jend3d7L+5Zdf5tnOOeO889L7mtTQmVT7MtQlS5ZUrV1++eXJdceNG5esn4tng7JnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPwWWXXZasd3Z2JuvtPM4+Z86cZL3Wn33Dhg1VaxdccEFy3VmzZiXrODvs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZc1Druuq1a9cm688991yyfsMNNyTrCxcuTNZTpk+fnqxv2rQpWR8zZkyyfuDAgaq1VatWJddFvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ5u4t21ipVPJyudyy7Z0rjh8/nqzXGstevnx51dqjjz6aXHfbtm3J+syZM5N1tJdSqaRyuWyVajX37Ga2xswOmdnOIcsuNbOXzOzj7HZCng0DyN9w3savlTT3jGX3Sdrq7ldK2po9BtDGaobd3V+R9MUZi+dLWpfdXydpQc59AchZvQfoOt19f3b/gKSqX7JmZj1mVjaz8sDAQJ2bA9Coho/G++ARvqpH+dy9191L7l46FyfDA0aKesN+0MwmSVJ2eyi/lgA0Q71h3yxpcXZ/saT0dZAAClfzenYze1rSLEkTzaxf0q8lrZD0ZzNbImmPpFub2eRIV+v702uZMKH+kc/HH388WZ8xY0ayblZxSBdtqGbY3X1RldJPc+4FQBNxuiwQBGEHgiDsQBCEHQiCsANB8FXSI8DSpUur1l5//fXkuhs3bkzWd+3alaxfe+21yTraB3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYRIPVV0729vcl1t27dmqzPnz8/WV+wIP31g9OmTatau/nmm5PrcvlsvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQTNkcXK3r3efOPXNOz+86cuRI3dtes2ZNsr5w4cJkfdy4cXVve6RqaMpmACMDYQeCIOxAEIQdCIKwA0EQdiAIwg4EwfXswU2dOjVZr/W98ffcc0+y/uyzz1at3X777cl1P/3002T93nvvTdbHjx+frEdTc89uZmvM7JCZ7Ryy7AEz22dmO7Kfec1tE0CjhvM2fq2kSqdR/dbdu7OfF/NtC0Deaobd3V+R9EULegHQRI0coLvbzN7N3uZPqPYkM+sxs7KZlQcGBhrYHIBG1Bv230n6kaRuSfslraz2RHfvdfeSu5c6Ojrq3ByARtUVdnc/6O4n3f2UpN9LSh/SBVC4usJuZpOGPLxZ0s5qzwXQHmpez25mT0uaJWmipIOSfp097pbkkvok/cLd99faGNezjzzffvttsv7aa69Vrd14443JdWv927zllluS9WeeeSZZH4lS17PXPKnG3RdVWLy64a4AtBSnywJBEHYgCMIOBEHYgSAIOxAEl7iiIWPHjk3WZ82aVbU2atSo5LonTpxI1p9//vlk/cMPP6xau/rqq5PrjkTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkfT5558n6xs2bEjWX3311aq1WuPotVx//fXJ+lVXXdXQ7x9p2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs49wtabcevLJJ5P1p556Klnv7+8/656Gq9b17l1dXcm6WcVvVA6LPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4+zng6NGjyfoLL7xQtfbQQw8l1/3oo4/q6ikPs2fPTtZXrFiRrF933XV5tjPi1dyzm9lkM9tmZrvNbJeZ/TJbfqmZvWRmH2e3E5rfLoB6Dedt/AlJy9z9Gkn/JOkuM7tG0n2Strr7lZK2Zo8BtKmaYXf3/e7+Vnb/a0nvS7pC0nxJ67KnrZO0oFlNAmjcWR2gM7MuST+R9BdJne6+PysdkNRZZZ0eMyubWbnWedoAmmfYYTezcZLWS1rq7n8dWnN3l+SV1nP3XncvuXupo6OjoWYB1G9YYTez0RoM+h/d/fTXiR40s0lZfZKkQ81pEUAeag692eB1gqslve/uvxlS2ixpsaQV2e2mpnQ4Ahw7dixZ37t3b7J+2223Jetvv/32WfeUlzlz5iTrDz74YNVara+C5hLVfA1nnH2apJ9Les/MdmTLlmsw5H82syWS9ki6tTktAshDzbC7+3ZJ1f6L/Wm+7QBoFk6XBYIg7EAQhB0IgrADQRB2IAgucR2mb775pmpt6dKlyXW3b9+erH/wwQd19ZSHefPmJev3339/st7d3Z2sjx49+qx7QnOwZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIMKMs/f19SXrjzzySLL+8ssvV63t2bOnnpZyc9FFF1WtPfzww8l177zzzmR9zJgxdfWE9sOeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCCDPOvn79+mR99erVTdv2lClTkvVFixYl6+efn/5r6unpqVobO3Zscl3EwZ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Iwd08/wWyypD9I6pTkknrdfZWZPSDp3yQNZE9d7u4vpn5XqVTycrnccNMAKiuVSiqXyxVnXR7OSTUnJC1z97fMbLykN83spaz2W3f/j7waBdA8w5mffb+k/dn9r83sfUlXNLsxAPk6q8/sZtYl6SeS/pItutvM3jWzNWY2oco6PWZWNrPywMBApacAaIFhh93MxklaL2mpu/9V0u8k/UhStwb3/Csrrefuve5ecvdSR0dHDi0DqMewwm5mozUY9D+6+wZJcveD7n7S3U9J+r2kqc1rE0CjaobdzEzSaknvu/tvhiyfNORpN0vamX97APIynKPx0yT9XNJ7ZrYjW7Zc0iIz69bgcFyfpF80pUMAuRjO0fjtkiqN2yXH1AG0F86gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFHzq6Rz3ZjZgKQ9QxZNlHS4ZQ2cnXbtrV37kuitXnn29g/uXvH731oa9u9t3Kzs7qXCGkho197atS+J3urVqt54Gw8EQdiBIIoOe2/B209p197atS+J3urVkt4K/cwOoHWK3rMDaBHCDgRRSNjNbK6ZfWhmn5jZfUX0UI2Z9ZnZe2a2w8wKnV86m0PvkJntHLLsUjN7ycw+zm4rzrFXUG8PmNm+7LXbYWbzCuptspltM7PdZrbLzH6ZLS/0tUv01ZLXreWf2c1slKSPJP2LpH5Jb0ha5O67W9pIFWbWJ6nk7oWfgGFmMyUdlfQHd782W/aopC/cfUX2H+UEd/9Vm/T2gKSjRU/jnc1WNGnoNOOSFkj6VxX42iX6ulUteN2K2LNPlfSJu3/m7n+T9CdJ8wvoo+25+yuSvjhj8XxJ67L76zT4j6XlqvTWFtx9v7u/ld3/WtLpacYLfe0SfbVEEWG/QtLeIY/71V7zvbukLWb2ppn1FN1MBZ3uvj+7f0BSZ5HNVFBzGu9WOmOa8bZ57eqZ/rxRHKD7vunuPkXSTZLuyt6utiUf/AzWTmOnw5rGu1UqTDP+d0W+dvVOf96oIsK+T9LkIY9/kC1rC+6+L7s9JGmj2m8q6oOnZ9DNbg8V3M/ftdM03pWmGVcbvHZFTn9eRNjfkHSlmf3QzMZI+pmkzQX08T1mdnF24ERmdrGkOWq/qag3S1qc3V8saVOBvXxHu0zjXW2acRX82hU+/bm7t/xH0jwNHpH/VNK/F9FDlb7+UdI72c+uonuT9LQG39b9nwaPbSyRdJmkrZI+lvSypEvbqLf/kvSepHc1GKxJBfU2XYNv0d+VtCP7mVf0a5foqyWvG6fLAkFwgA4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgvh//v1TaNV8b54AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(digit.reshape(28,28), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed things up, we will get a sample of 10000 observations. We set Numpy's random seed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15795,   860, 54886, ..., 49222, 48115, 40647])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 10000\n",
    "np.random.seed(42)\n",
    "random_sample_index = np.random.randint(0, mnist.data.shape[0], sample_size)\n",
    "random_sample_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_sample_data = mnist.data[random_sample_index]\n",
    "mnist_sample_target = mnist.target[random_sample_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'>Exercise</font>\n",
    "\n",
    "Use PCA to reduce the mnist sample dimensionality and create a classifier that correctly classifies the images, using as the scorer the F1 score (there are multiple f1 scores for multiclass, choose the one you think fits best the problem, the [documentation can help](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html)). The greater the f1-score the better the classifier. \n",
    "<!--A good classifier would have a F1 above 0.99-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check how the target classes are distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.1156\n",
       "7    0.1017\n",
       "2    0.1017\n",
       "3    0.1015\n",
       "8    0.0999\n",
       "6    0.0980\n",
       "9    0.0974\n",
       "0    0.0971\n",
       "4    0.0960\n",
       "5    0.0911\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(mnist_sample_target).value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see there is no class imbalance, so we can use F1 micro average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "mnist_sample_data = scaler.fit_transform(mnist_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_pca = pca.fit_transform(mnist_sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.03907967e+01, -1.23630773e+01,  3.31352667e+00, ...,\n",
       "         1.96280671e+00,  7.71974772e-01, -2.14867729e-01],\n",
       "       [ 1.03672258e+01, -9.25699210e+00, -1.98309677e+00, ...,\n",
       "        -1.96507031e-01,  3.48332786e-01, -3.03638249e-01],\n",
       "       [-8.43079556e+00, -8.90042145e-01,  2.05460606e+00, ...,\n",
       "         2.10377726e-02,  2.70538203e-01, -9.29326815e-01],\n",
       "       ...,\n",
       "       [-5.18654089e-01,  1.25138290e+00,  7.14945114e+00, ...,\n",
       "        -1.22736471e+00, -6.72415306e-01,  1.68191417e-01],\n",
       "       [-4.57313498e-01, -2.20664871e+00, -9.80935474e-01, ...,\n",
       "        -4.82266853e-01, -7.14119409e-01, -4.71904286e-01],\n",
       "       [ 1.04187644e+00, -2.46688209e+00, -9.85088034e+00, ...,\n",
       "        -1.83735194e-01, -9.36201908e-03, -9.86507885e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply logistic regression to transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver=\"lbfgs\", # handle L2 or no penalty\n",
    "                         max_iter=2000,  # maximum #iterations for solver to converge\n",
    "                         dual=False)     # when sample_size > number_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf_results = cross_val_score(clf,\n",
    "                              mnist_pca,\n",
    "                              mnist_sample_target,\n",
    "                              scoring=\"f1_micro\",\n",
    "                              cv=10\n",
    "                             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9141"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

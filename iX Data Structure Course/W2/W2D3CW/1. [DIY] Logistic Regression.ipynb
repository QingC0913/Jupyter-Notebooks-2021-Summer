{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'> Logistic Regression </font>\n",
    "\n",
    "In this module, we'll be exploring how to build a logistic regression model using scikit-learn. Remember, logistic regression is a binary classification algorithm, so instead of predicting a number (regression) or a group of labels (i.e. multi-class classification) we'll be predicting either true or false. Let's start by importing our usual toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(rc={'figure.figsize':(6,6)}) #Set our seaborn aesthetics (we're going to customize our figure size)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Breast Cancer Data </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [Wisconsin Breast Cancer Dataset](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)). Is a dataset that contains measurements computed from digitized images of fine needle aspirate (FNA) breast mass samples. The goal is to predict whether the cells are benign (non-cancerous) or malignant (cancerous).\n",
    "\n",
    "The images look like this one:\n",
    "\n",
    "![title](media/breast_cancer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the cancer dataset as \"cancer_data\" and view its keys\n",
    "cancer_data = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the \"DESCR\" key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is a binary classification problem, where the target variable can be either a negative or positive. It is encoded as a 0 or a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the first 20 values using the \"target\" key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the target labels (the names the 0 and 1 represent) by reading the key `target_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the \"target_names\" key to see the target labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the 0 means the sample is malignant and a 1 means its benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe called \"cancer_df\" using the data we loaded.\n",
    "# the columns are from the \"feature_names\" key\n",
    "cancer_df = pd.DataFrame(...)\n",
    "\n",
    "# add a new column, \"target\", from the \"target\" key\n",
    "cancer_df[\"target\"] = ...\n",
    "\n",
    "cancer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The independent variables are measurements taken on the cell images, mostly measures of the cell nucleii**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the counts of the \"target\" column. Hint: use value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that 62.7% of the cancers are benign and 37.3% are malignant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Logistic Regression in Scikit-learn </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LogisticRegression class from scikit-learn\n",
    "from sklearn.model_selection import ...\n",
    "\n",
    "# import train_test_split from from scikit-learn\n",
    "from sklearn.linear_model import ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> 1) Let's split our data set into train test split </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "y = ...\n",
    "\n",
    "# use 20% of the dataset as the testing set\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train: ',X_train.shape)\n",
    "print('X_test: ',X_test.shape)\n",
    "print('y_train: ',y_train.shape)\n",
    "print('y_test ',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This estimator (or classifier, another name for classification problems estimators) is used the same way as LinearRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'>  2) Create and fit the logistic regression model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='#eb3483'> 3) See the model predictions </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = ...\n",
    "\n",
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the `predict` method directly outputs the predicted class (0 or 1). If we want to see the probabilities the model assign to each class (that means, how confident the method is that the observation belongs to one class or the other) we can use the method `predict_proba`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.set_printoptions(suppress=True) # uncomment this to suppress scientific notation\n",
    "predictions_probabilities = ...\n",
    "predictions_probabilities[:10]\n",
    "\n",
    "# why are there two columns of results here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(predictions_probabilities[:,0], bins= 10, kde = False, label = 'Prob0', axlabel = 'Prob0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(predictions_probabilities[:,1], bins = 10, kde = False, label = 'Prob1', axlabel = 'Prob1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how each class predictions change with the predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_df = pd.DataFrame(predictions_probabilities)\n",
    "probs_df = round(probs_df, 2)\n",
    "probs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how the model computes the probabilities and assigns a class given a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test.reset_index().copy()\n",
    "X[\"target\"] = y_test.tolist()\n",
    "X[\"prediction\"] = predictions\n",
    "X = pd.concat([X, probs_df], axis=1)\n",
    "X[[\"target\", \"prediction\", 0, 1]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the threshold for this split is 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model, has many hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use get_params() to check the model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important hyperparameters are:\n",
    "- **penalty** : `l1` or `l2` the regularization method\n",
    "- **fit_intercept**: `True` or `False`, if you want the intercept in the linear model\n",
    "- **C** : float, inverse of regularization; the lower the float, the more the model will regularize the feature coefficients\n",
    "\n",
    "Extra reading on regularization: https://towardsdatascience.com/over-fitting-and-regularization-64d16100f45c and https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

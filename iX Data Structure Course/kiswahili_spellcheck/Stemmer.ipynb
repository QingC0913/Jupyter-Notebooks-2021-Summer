{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "minus-dancing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For learning the prefixes/grammar stuff i used the wiki (https://en.wikipedia.org/wiki/Swahili_grammar)\n",
    "\n",
    "\n",
    "\n",
    "noun_prefixes={'m':['','w','a','i','y','e'],'j':['','i'],'k':['i','u','w'], \n",
    "               'c':['h'],'v':['i','y'],'u':['','w'],'w':['','a','e'],'n':['','y']}\n",
    "\n",
    "# I chose to make a dictionary of prefixes because then I can quickly exclude words like 'simba' which based \n",
    "# on the first letter clearly do not have a prefix\n",
    "\n",
    "problem_noun_prefixes=['wa','we','me','ji','mb','mv','nd']\n",
    "\n",
    "#This list is not set in stone at all but just the prefixes that seem to cause problems based on my understanding of the wiki\n",
    "\n",
    "\n",
    "adjective_prefixes={'m':['','wi','we','i','ye','a','e','u','nao','lio','takao','sio','namo','limo','takamo','simo'],\n",
    "                    'w':['a','e','anao','alio','atakao','asio'],'j':['i','e'],'k':['i','u','wi','we','inacho','ilicho',\n",
    "                                                                                   'itakacho','isicho','unako','uliko',\n",
    "                                                                                   'utakako','usiko'],\n",
    "                    'c':['he'],'v':['i','ye','inavyo','ilivyo','itakavyo','isivyo'],'p':['a','e','anapo','alipo','atakapo',\n",
    "                                                                                         'asipo'],\n",
    "                    'n':['','nyi','nye','iliye','itakaye','isiye','inaye'],'u':['naye','liye','takaye','siye','nao','lio','takao','sio'],\n",
    "                    't':['ulio','utakao','usio','unao'],'a':['naye','liye','takaye','siye'],'i':['nayo','liyo','takayo','siyo'],\n",
    "                    'l':['inalo','ililo','litakalo','isilo'],'y':['anayo','aliyo','atakayo','asiyo'],\n",
    "                    'z':['inazo','ilizo','itakazo','isizo']}\n",
    "adjective_prefixes_with_suffixes= [('mw','mo'),('mw','o'),('m','mo'),('m','o'),('ni','ye'),('u','ye'),('u','o'),\n",
    "                                   ('tu','o'),('a','ye'),('wa','o'),('i','yo'),('li','lo'),('ya','yo'),('ki','cho'),\n",
    "                                   ('vi','vyo'),('zi','zo'),('ku','ko'),('pa','po')]\n",
    "\n",
    "#some of the adjectives have matching suffixes so i just paired them and remove both if both are in the word\n",
    "\n",
    "problem_adjective_prefixes=['mb','nd','ng','nj','mv','nz']\n",
    "\n",
    "verb_prefixes_subject_object={'n':['','i'],'h':['u','a','am','au','ai','atu','ayu','awa','ali','aya','aki','avi','azi','aku',\n",
    "                                                'apa','amu'],'s':['i'],'u':[''],'t':['u','w'],'k':['u','i','kw'],'c':['h'],\n",
    "                             'm':['','w','u'],'a':[''],'w':['','a',],'y':['','a','u'],'i':[''],'l':['','i'],'v':['i','y'],\n",
    "                             'z':['','i'],'p':['','a']}\n",
    "\n",
    "\n",
    "\n",
    "verb_prefixes_tense={'s':[('ingali',['a']),('inge',['a']),('i',['a','e'])],'k':[('a',['e']),('i',['a']),('u',['a'])],\n",
    "                     'n':[('gali',['a']),('ge',['a']),('a',['a'])],'t':[('a',['a']),('o',['a'])],'a':[('',['a'])],\n",
    "                    'h':[('u',['a'])],'l':[('i',['a'])],'m':[('e',['a'])],'j':[('a',['a'])]}\n",
    "                     \n",
    "#The list inside the tuples is the list of corresponding endings from the wiki. I dont understand what they are used\n",
    "# for (especially in relation to the suffixes) but I chose to add them just in case they ever become useful\n",
    "# i realized later that literall only two prefixes have non 'a' endings but i just left it\n",
    "                     #'':[('',['i','e','a'])] this is the endings for no tense prefix if they are ever useful\n",
    "                     \n",
    "\n",
    "\n",
    "verb_prefixes_relative={'y':['o','e'],'o':[''],'l':['o'],'v':['yo'],'m':['o'],'k':['o'],'c':['ho'],'z':['o'],'p':['o']}\n",
    "\n",
    "verb_suffixes=['ana','ia','wa','lia','ea','lea','isha','lisha','esha','lesha','eza','iza','was','iwa','ewa','liwa','lewa',\n",
    "               'ka','ika','eka','lika','leka']\n",
    "\n",
    "#I didnt end up using suffixes in the final code but the list is here in case its every useful\n",
    "\n",
    "def lemmatize_noun(word):\n",
    "    possible_prefixes=noun_prefixes.get(word[0],-1)\n",
    "    stem=word\n",
    "    prob=.9  #i put .9 bc I cant be sure i have considered all possible error so .9 is best and 1 can be if a human checks it\n",
    "    if possible_prefixes!=-1:\n",
    "        for i in reversed(possible_prefixes): #reversed bc i want to test the longest prefix first so for example 'm' cant be confused with 'mw'\n",
    "            if stem[1:].startswith(i):\n",
    "                stem=stem[len(i)+1:]\n",
    "                for b in problem_noun_prefixes: \n",
    "                    if word.startswith(b):\n",
    "                        prob=.7  #this number is totally arbitrary but basically Im fairly confident it gets nouns right\n",
    "                                 # as long as the prefix isnt in the problem prefix list, even then i think its probably right\n",
    "                return (stem,prob)              \n",
    "        return (stem,prob) \n",
    "    return (stem,prob) \n",
    "\"\"\"\n",
    "Problems:\n",
    "1.The prefix ma- may merge with a following i to become me- as in meno \"teeth\" (singular: jino).\n",
    "2. Some nouns may also simply have stems which start with ji- such as jina \"name\" (plural: majina).\n",
    "3.Wa- is often present only as w- when the stem begins with /a/ as in wanafunzi \"students\"\n",
    "(singular: mwanafunzi). A following i may merge with the a of this prefix, forming we- as in wezi\n",
    "\"thieves\" (singular: mwizi). \n",
    "4.The n of the prefix is a prenasalising mutation of the following consonant and is never syllabic unless \n",
    "the noun would otherwise only have one syllable. It becomes m before b and v. In stems beginning with w such\n",
    "as ‑wili \"two\", this mutates to mb. Before vowels it is present as ny. Before d, z, j and g it is n. L and r \n",
    "become nd. Before other consonants, it disappears unless it is required as a syllabic consonant to prevent the\n",
    "noun from having only one syllable, such as in nchi \"country, land\". The plural form of class 11 nouns is formed\n",
    "this way, dropping the u- and then applying these rules (for example ulimi → ndimi \"tongue\" → \"tongues\", ukuta → \n",
    "kuta \"wall\" → \"walls\"), except that short nouns with a monosyllabic stem preserve the u- in the plural for \n",
    "reasons of stress, adding ny- before it to form the plural, such as uso \"face\", which becomes nyuso in the plural.\n",
    "\n",
    "^^^^ is grammatical things i copy pasted from the wiki that explain what rules my code will be messed up by\n",
    "\"\"\" \n",
    "\n",
    "def lemmatize_adj(word):\n",
    "    stem=word\n",
    "    prob=.9 #same explanantion as nouns\n",
    "    for i in adjective_prefixes_with_suffixes: #i just split it into two steps. This step is for prefixes with a suffix\n",
    "        if stem.startswith(i[0]) and stem.endswith(i[1]):\n",
    "            stem=stem[len(i[0]):len(stem)-len(i[1])]\n",
    "            return (stem,prob) #I dont think there are any errors to check for this one\n",
    "    possible_prefixes=adjective_prefixes.get(word[0],-1)\n",
    "    if possible_prefixes!=-1: #if the prefix isnt one of the ones with a suffix, then this step tests for the rest\n",
    "        for i in reversed(possible_prefixes):\n",
    "            if stem[1:].startswith(i):\n",
    "                stem=stem[len(i)+1:]\n",
    "                for b in problem_adjective_prefixes:    \n",
    "                    if word.startswith(b):\n",
    "                        prob=.7         #same explanation as nouns\n",
    "                        return (stem,prob) \n",
    "        return (stem,prob)\n",
    "    return (stem,prob)\n",
    "\"\"\"\n",
    "Problems\n",
    "1.The N- prefix in classes 9 and 10 exhibits considerable variation. On adjectives with stems of more than one syllable,\n",
    "it only appears as a prenasalisation of the following consonants: b → mb, d → nd, g → ng, j → nj, l → nd, r → nd, v → mv,\n",
    "w → mb, z → nz. Elsewhere, it disappears. In addition, the monosyllabic adjective stem -pya \"new\" has\n",
    "the form mpya, whereby the m- constitutes the stressed syllable.\n",
    "\n",
    "^^^ Also pasted from wiki\n",
    "\"\"\"\n",
    "def lemmatize_verb_subject_object(word):\n",
    "    stem=word\n",
    "    possible_prefixes=verb_prefixes_subject_object.get(word[0],-1)\n",
    "    if possible_prefixes!=-1: #if the prefix isnt one of the ones with a suffix, then this step tests for the rest\n",
    "        for i in reversed(possible_prefixes):\n",
    "            if stem[1:].startswith(i):\n",
    "                stem=stem[len(i)+1:]\n",
    "                return (stem,i)        #Im returning the stem so i cant estimate how wrong I think I am\n",
    "        return (stem,'N/A')  #If there is no stem N/A is returned\n",
    "    return (stem,'N/A')\n",
    "def lemmatize_verb_tense(word):\n",
    "    stem=word\n",
    "    possible_prefixes=verb_prefixes_tense.get(word[0],-1)\n",
    "    if possible_prefixes!=-1: #if the prefix isnt one of the ones with a suffix, then this step tests for the rest\n",
    "        for i in reversed(possible_prefixes):\n",
    "            if stem[1:].startswith(i[0]):\n",
    "                stem=stem[len(i[0])+1:]\n",
    "                return (stem,i)\n",
    "        return (stem,'N/A')\n",
    "    return (stem,'N/A')\n",
    "def lemmatize_verb_relative(word):\n",
    "    stem=word\n",
    "    possible_prefixes=verb_prefixes_relative.get(word[0],-1)\n",
    "    if possible_prefixes!=-1: #if the prefix isnt one of the ones with a suffix, then this step tests for the rest\n",
    "        for i in reversed(possible_prefixes):\n",
    "            if stem[1:].startswith(i):\n",
    "                stem=stem[len(i)+1:]\n",
    "                return (stem,i)\n",
    "        return (stem,'N/A')\n",
    "    return (stem,'N/A')\n",
    "def lemmatize_verb_suffix(word):   #I didnt use this in the final lemmatize_verb() but its here in case its ever useful\n",
    "    stem=word\n",
    "    suffix=0\n",
    "    while suffix==0:      #a word can have multiple suffixes, so this runs until the word doesnt end in a suffix\n",
    "                            # except this doesnt work because the a is removed when the suffixes are stacked\n",
    "        for i in reversed(verb_suffixes):\n",
    "            if stem.endswith(i):\n",
    "                stem=stem[:len(stem)-len(i)]\n",
    "        suffix-=1\n",
    "    return stem          \n",
    "    \n",
    "'''\n",
    "This gets messed up by stacked prefixes. So like 'likianishwa' has the root 'la' but the suffixes are stacked.\n",
    "Except the 'a' gets removed in between which is why my code above fails. I would have tried to fix this but I ended up\n",
    "excluding removing the suffix from the final code anyway\n",
    "'''\n",
    "\n",
    "    \n",
    "def lemmatize_verb(word):\n",
    "    prob=.75 #Im way less confident with verbs\n",
    "    output=lemmatize_verb_subject_object(word)\n",
    "    stem=output[0]\n",
    "    prefix_list[]\n",
    "    if output[1]=='N/A':  #This can just help me know which prefixes a word has so like [1,1,0,1]==no relative prefix but everything else\n",
    "        prefix_list.append(0)\n",
    "    else:\n",
    "        prefix_list.append(1)\n",
    "    if len(output[1])==0: #the one letter prefixes seem to cause the most problems so if they have those im reducing the prob\n",
    "        prob-=.05  #Again this is arbitrary but i feel that if its the first prefix its maybe probably right so only a slight decrease\n",
    "    output=lemmatize_verb_tense(stem)\n",
    "    stem=output[0]\n",
    "    if output[1]=='N/A':\n",
    "        prefix_list.append(0)\n",
    "    else:\n",
    "        prefix_list.append(1)\n",
    "    if output[1]==0:\n",
    "        prob-=.1 #totally an arbitrary guess based on not liking single letter prefixes\n",
    "    output=lemmatize_verb_relative(stem)\n",
    "    stem=output[0]\n",
    "    if output[1]=='N/A':\n",
    "        prefix_list.append(0)\n",
    "    else:\n",
    "        prefix_list.append(1)\n",
    "    if output[1]==0:\n",
    "        prob-=.1 #totally an arbitrary guess based on not liking single letter prefixes\n",
    "    output=lemmatize_verb_subject_object(stem)\n",
    "    stem=output[0]\n",
    "    if output[1]=='N/A':\n",
    "        prefix_list.append(0)\n",
    "    else:\n",
    "        prefix_list.append(1)\n",
    "    if len(output[1])==1:\n",
    "        prob-=.4 # I feel like if its the last prefix and its a single letter the chance its wrong is extremely high\n",
    "    if prefix_list==[0,0,0,0]:\n",
    "        prob=.1           #As far as im aware verbs must have at least one prefix\n",
    "    if prefix_list==[1,1,1,1]:\n",
    "        prob+=.1          #Also just a feeling but i think if all prefixes are filled that bodes well\n",
    "    return (stem,prob)\n",
    "\n",
    "\"\"\"\n",
    "Problems:\n",
    "It jusprefixes at is terrible with single letter nd can get messed up super easily because of that.\n",
    "Hard coding is probably not the best solution for verbs especially given I dont think there are many\n",
    "indicators for when a word has a single letter prefix or the root just starts with the letter.\n",
    "Also suffixes pose an interesting question. As far as I understand, suffixes can completely alter the\n",
    "meaning of a word but sometimes they bareley change the meaning at all. I chose to exclude it from the final code\n",
    "because 1. it introduces a few more problems that I didnt solve and 2. Online swahili dictionaries seem to include\n",
    "suffixes as a part of the root.\n",
    "\"\"\"\n",
    "def lemmatize(word,tag):\n",
    "    if tag =='Noun':\n",
    "        return lemmatize_noun(word)\n",
    "    if tag == 'Adjective':\n",
    "        return lemmatize_adj(word)\n",
    "    if tag =='Verb':\n",
    "        return lemmatize_verb(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "concrete-detection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example for Normal Nouns:\n",
      "mtu ---> tu\n",
      "watu ---> tu\n",
      "mti ---> ti\n",
      "miti ---> ti\n",
      "jicho ---> cho\n",
      "macho ---> cho\n",
      "kitabu ---> tabu\n",
      "vitabu ---> tabu\n",
      "simba ---> simba\n",
      "funguo ---> funguo\n",
      "ufunguo ---> funguo\n",
      "utu ---> tu\n",
      "kula ---> la\n",
      "Example of errors:\n",
      "jina ---> na\n",
      "majina ---> jina\n",
      "wanafuzi ---> nafuzi\n",
      "mwanafuzi ---> anafuzi\n"
     ]
    }
   ],
   "source": [
    "print('Example for Normal Nouns:')\n",
    "example_nouns=['mtu','watu','mti','miti','jicho','macho','kitabu','vitabu','simba','funguo','ufunguo','utu','kula']\n",
    "for i in range(13):\n",
    "    print(example_nouns[i]+' ---> '+lemmatize_noun(example_nouns[i])[0])\n",
    "print('Example of errors:')\n",
    "example_error=('jina','majina','wanafuzi','mwanafuzi')\n",
    "for i in range(4):\n",
    "    print(example_error[i]+' ---> '+lemmatize_noun(example_error[i])[0])\n",
    "    \n",
    "'''\n",
    "I think this should show the error described by the pasted wiki text below the function. 'Majina' is the plural, but 'jina'\n",
    "by itself is both a stem and the singular so the 'ji' should be left alone when its just 'jina'.\n",
    "On the second error, 'anafuzi' is the stem which is obvious given 'mwanafuzi' and when its singular it only adds 'w'. \n",
    "But because 'wa' is also a prefix, the code thinks the root is 'nafuzi'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stretch-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Example:\n",
      "mmoja ---> moja\n",
      "kimoja ---> moja\n",
      "wawili ---> wili\n",
      "viwili ---> wili\n",
      "aliyekufa ---> kufa\n",
      "waliokufa ---> kufa\n",
      "N Class Nouns Messing it up:\n",
      "moja ---> oja\n",
      "mbili ---> bili\n"
     ]
    }
   ],
   "source": [
    "example_adjectives=['mmoja','kimoja','wawili','viwili','aliyekufa','waliokufa']\n",
    "example_error_N_class=['moja','mbili']\n",
    "print(\"Normal Example:\")\n",
    "for i in range(6):\n",
    "    print(example_adjectives[i]+' ---> '+lemmatize_adj(example_adjectives[i])[0])\n",
    "print('N Class Nouns Messing it up:')\n",
    "for i in range(2):\n",
    "    print(example_error_N_class[i]+' ---> '+lemmatize_adj(example_error_N_class[i])[0])\n",
    "'''\n",
    "N class nouns cause lots of problems with the root. 'moja' and 'mmoja' both having 'moja' as the root is an error that\n",
    "is super weird but the N class nouns mean that the adjectives describing them have very strange conjugations. Same thing\n",
    "with 'wawili' vs 'mbili'. They both have 'wili' as the root but the N class nouns has 'wili' conjugate to 'mbili'. But, I\n",
    "cant even hard code a solution because (it probably isnt) if bili was a stem, it would also conjugate to 'mbili' to describe\n",
    "an N class noun so the code would know whether to turn 'mbili' into 'wili' or 'bili'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "applicable-auckland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nilipokupikia ---> lipokupikia\n",
      "lipokupikia ---> pokupikia\n",
      "pokupikia ---> kupikia\n",
      "kupikia ---> pikia\n"
     ]
    }
   ],
   "source": [
    "print('nilipokupikia ---> '+ lemmatize_verb_subject_object('nilipokupikia')[0])\n",
    "print('lipokupikia ---> '+ lemmatize_verb_tense('lipokupikia')[0])\n",
    "print('pokupikia ---> '+ lemmatize_verb_relative('pokupikia')[0])\n",
    "print('kupikia ---> '+ lemmatize_verb_subject_object('kupikia')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "enabling-billy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs:\n",
      "nilisema ---> lisema\n",
      "unasema ---> nasema\n",
      "walisema ---> lisema\n",
      "ulisema ---> lisema\n",
      "nilivyosema ---> livyosema\n",
      "vinafaa ---> nafaa\n",
      "anakupenda ---> nakupenda\n",
      "nilifungua ---> lifungua\n",
      "hakifai ---> fai\n"
     ]
    }
   ],
   "source": [
    "print('Verbs:')\n",
    "list_verbs=['nilisema','unasema','walisema','ulisema','nilivyosema','vinafaa','anakupenda','nilifungua','hakifai',]\n",
    "for i in range(9):\n",
    "    print(list_verbs[i]+' ---> '+lemmatize_verb(list_verbs[i])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "large-scholar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of Errors:\n",
      "walipiga ---> iga\n",
      "nipe ---> e\n",
      "hatuwezi ---> ezi\n"
     ]
    }
   ],
   "source": [
    "print('Example of Errors:')\n",
    "list_errors=['walipiga','nipe','hatuwezi']\n",
    "for i in range (3):\n",
    "    print(list_errors[i]+' ---> '+lemmatize_verb(list_errors[i])[0])\n",
    "    \n",
    "'''\n",
    "This should demonstrate the issue with single letter prefixes. The root is 'piga' but because the conjugated verb\n",
    "lacks a second subject/object prefix the code see the 'p' at the start of 'piga' as the second subject/object prefix\n",
    "and removes it. The same issue with the next two. Also 'nipe' has the root 'pa' but to be honest i dont understand at all\n",
    "why the 'a' is replace by 'e'. I think it maybe be related to the endings connected to the tenses.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "great-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verbs with Suffixes:\n",
      "lilivunjika ---> vunj\n",
      "lilivunjwa ---> vunj\n",
      "alivunja ---> vunja\n"
     ]
    }
   ],
   "source": [
    "print('Verbs with Suffixes:')\n",
    "verb_with_suffixes=['lilivunjika','lilivunjwa','alivunja']\n",
    "for i in range(3):\n",
    "    print(verb_with_suffixes[i]+' ---> '+lemmatize_verb_suffix(lemmatize_verb(verb_with_suffixes[i])[0]))\n",
    "    \n",
    "'''\n",
    "Another reason i removed suffixes is because of the descrepency between 'vunj' and 'vunja' shown here. With short and \n",
    "common verbs (terms for verbs originating in the swahili language) i could add the 'a' at the end if i removed a suffix\n",
    "but with borrowed verbs, the verbs doesnt always end in 'a' so the root would be wrong.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "above-netherlands",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suffix Errors/Problems:\n",
      "andika ---> andikianishwa ---> andikianish\n",
      "la ---> liwa ---> \n",
      "nya ---> nyewa ---> ny\n",
      "pa ---> pewa ---> p\n",
      "dai ---> daiwa ---> da\n",
      "jaribu ---> jaribiwa ---> jarib\n"
     ]
    }
   ],
   "source": [
    "print('Suffix Errors/Problems:')\n",
    "errors=['andikianishwa','liwa','nyewa','pewa','daiwa','jaribiwa']\n",
    "original=['andika','la','nya','pa','dai','jaribu']\n",
    "for i in range (6):\n",
    "    print(original[i]+' ---> '+errors[i]+' ---> '+lemmatize_verb_suffix(errors[i]))\n",
    "    \n",
    "'''\n",
    "The issue with borrowed verbs can be seen here with dai and jaribu. The first error is the suffix stacking though. And\n",
    "the second is just a weird one where liwa itself is a prefix but also 'la' plus the 'iwa' suffix.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

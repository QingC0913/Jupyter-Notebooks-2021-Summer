{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='#eb3483'> Intro to Deep Learning - Image Classificatoin </font>\n",
    "In this notebook we'll do a lightnig quick demonstration of how to build an image classifier using keras. Processing images (especially where it's hard to do feature engineering), is where deep learning shines - so this is a great skill to have in your toolbox!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> MNIST </font>\n",
    "For this example we'll be working with the MNIST dataset - a database of handwritten digits. MNIST is kind of like the iris or titanic data set of image classification. Everyone's done it at some point when they started learning machine learning - it's a rite of passage (despite not being a terribly interesting problem)!\n",
    "\n",
    "Lucky for us Keras has the dataset built-in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    " \n",
    "# Load pre-shuffled MNIST data into train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each sample in our data set is a 28 by 28 pixel image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peak at what our data looks like using matplotlib's imshow function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6c20d1bd0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that each pixel has a value between 0 and 255 (it's an intensity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].min(), X_train[0].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Data Pre-Processing </font>\n",
    "To get our data ready for a convolutional neural network (i.e. fancy way to say a neural network with a special type of layer for processing images), we'll need to reshape our data into a tensor (i.e. a 3 dimensional matrix). We'll use numpy's handy reshape functionality for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape into #samples x (28 x 28 pixels) x (added dimension to make it a tensor)\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also convert everything to a float and get the values between 0 and 1 instead of 0 and 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert data to floats\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#Convert values from [0,255] to [0,1]\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that this is a multi-class classification problem (there are 10 digits). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at all the possible categories we need to predict\n",
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for this we're going to ask our neural network to output a probability for each digit (i.e. for sample 1 it could output 80% chance it's a 2 and 20% chance its a 7). To do that we need to convert our y (target variable) to one-hot encoding. We'll do this using np_utils from keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now instead of one target we have 10!\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='#eb3483'> Building a Model </font>\n",
    "We're going to follow the same process that we did in the other deep learning notebook. \n",
    "1. Create a Model\n",
    "2. Add Layers\n",
    "3. Compile it\n",
    "4. Train it\n",
    "5. Evaluate it\n",
    "The only difference is that we're going to use different layers, and a different loss function!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the Sequential Model from keras.models and instantiate a model\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Add Layers\n",
    "For this model we're going to use a special type of neural network layer called a convolutional later (and a flatten layer to go from convolution back to dense layer). Don't fret too much about the details - you can check out a whole host of resources on convolutional neural networks linked in the slides. Here's a little diagram about what a convolutional neural network looks like:\n",
    "\n",
    "![title](media/CNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We'll import the three kinds of layers we'll need for this model from keras.layers\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "#We'll add two convolutional layers (these are great at extracting features from images)\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "#This helps go from a convolutional layer to a dense layer\n",
    "model.add(Flatten())\n",
    "#For our output layer we want one neuron per category and we're going to use softmax to get probabilities\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile Model\n",
    "We're going to use the same optimizer (ADAM) as before - but this time we're going to use categorical cross entropy instead of binary cross entropy (same idea but works for multi-class classification instead of binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',  # Set ADAM as our optimizer\n",
    "              loss='categorical_crossentropy',  #Set our loss function to be categorical cross entropy\n",
    "              metrics=['accuracy']) #Ask Keras to track accuracy for us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fit the Model\n",
    "This will take awhile!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/connorlawless/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 58s 973us/step - loss: 0.1267 - accuracy: 0.9619 - val_loss: 0.0538 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb6b1c4a810>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train,  #Feed in our training data\n",
    "          validation_data=(X_test, Y_test),  #Our testing data \n",
    "          epochs=1) #For this (because we have so much data, we're only going to do 1 epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the Model\n",
    "Instead of plotting our accuracy and loss curves, I'm just going to ask Keras to evaluate our final model (we won't do early stopping). Keras has a great function called evaluate to do that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out the help doc\n",
    "model.evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy:  0.9830999970436096\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Model Accuracy: ', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah - 98% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Make Predictions\n",
    "Let's make some predictions on our test data, and look at images of an example that we got wrong (to see how bad/good our model is)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's just predict the final categories (i.e. the digits)\n",
    "preds = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's compare our predictions to the true categories\n",
    "result = y_test == preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now pull out specific examples we got wrong and plot them. Let's look at the one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our prediction was 0 and the actual answer was 6\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 1\n",
    "plt.imshow(X_test[~result][sample])\n",
    "print(f'Our prediction was {preds[~result][sample]} and the actual answer was {y_test[~result][sample]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play around with picking different samples (i.e. changing 1 in the above block). You'll notice alot of the mistakes are pretty reasonable!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
